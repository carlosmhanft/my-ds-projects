# -*- coding: utf-8 -*-
"""Pokemon_Cluster.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GYwMdsldC4iGq3mZTL2XJw5O3lRGxAaS
"""

# !pip install kaggle
# !kaggle datasets list -s 'Pokémon'
# !kaggle datasets download -d rounakbanik/pokemon
# !sudo apt-get install unzip

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/pokemon.csv')

df.head()

"""# **Organizando base:**

    1. Levantando alguns pontos encontrados (valores nulos)
    2. Tratando estes valores nulos e textos incorretos
    3. Coluna "type2" será igual a "type1" quando ela for vazia**
    4. etc.

"""

# Alguns valores nulos ocorreram por conta de limitações na extração desses dados
# onde os pokémons com nulos na altura e peso são aqueles que possuem diferentes formas (O caso dos Alolan)
# ou possuem diferentes formas físicas (Hoopa) ou diferenças entre o tipo do jogo (Lycanroc)
# vamos desconsiderar estes dados em uma modelagem futura.

# Fonte: https://www.kaggle.com/rounakbanik/pokemon/discussion/115718

df[df.weight_kg.isna()].loc[:,['name','weight_kg','height_m']]

#Ajustar o conteúdo da coluna classfication (24), tirando o termo Pokémon
df.classfication = df.classfication.replace('Pokémon','',regex=True)


# incluir valor na coluna type2 onde há valores nulos
df.type2 = np.where(df.type2.isna(),df.type1,df.type2)


# Corrigindo um valor da coluna que estava com texto estranho ao invés do valor 255
df.capture_rate = df.capture_rate.replace('30 (Meteorite)255 (Core)','255')


#Depois de ajustar a coluna, vamos transformar no tipo adequado de dado
df.capture_rate = df.capture_rate.astype('int64')


# Ajustar coluna de altura para valores nulos, colocar a média onde for nulo
df.height_m = np.where(df.height_m.isna(),
                              df.height_m.mean(),
                              df.height_m)


# Ajustar %masculino para valores nulos, colocar a média onde for nulo
df.percentage_male = np.where(df.percentage_male.isna(),
                                     df.percentage_male.mean(),
                                     df.percentage_male)


# Ajustar coluna de peso para valores nulos, colocar a média onde for nulo
df.weight_kg = np.where(df.weight_kg.isna(),
                               df.weight_kg.mean(),
                               df.weight_kg)

# separando as colunas por assunto, pra facilitar...
cols = df.columns.values

col_ability  = cols[0]
cols_against = cols[1:19]
cols_status  = cols[19:]

# Vamos colocar os nomes dos Pokémon como índice por serem valores únicos

df.set_index(df.name,inplace = True)

# Separando as colunas mais relevantes pra analisar
status = ['hp',
          'attack',
          'defense', 
          'speed',
          'sp_attack',
          'sp_defense',
          'base_total',
          'type1',
          'type2',
          'capture_rate',
          'height_m',
          'weight_kg',
          'classfication',
          'generation',
          'is_legendary']

df_status = df[status]

"""# **Análises rápidas sobre a base**

    *   Algumas análises descritivas para conhecermos melhor a base que estamos trabahando
    *   Coisas iniciais como agrupar por um determinado tipo e ver média, desvio padrão, etc.
    *   Aqui fica livre pra fazer o quanto quiser de visualizações (Lembrando: Às vezes, menos é mais ! )
    *   Divirta-se

"""

# Estatísticas descritivas

df_status.describe().round(2)

# Visão agregada por tipo de pokemon (usndo os pontos base)

df_status.groupby('type1').agg(
    qtde   = ('base_total','count'),
    minimo = ('base_total','min'),
    maximo = ('base_total','max'),
    media  = ('base_total','mean'),
    dsvp   = ('base_total','std')
    ).sort_values('media',ascending=False).round(1)

# Visão agregada por Tipo vs. (Pontos Base / Ataque / HP /  Geração) de pokemon
# Na hora de fazer o sort, precisa passar um tupla com as colunas a serem ordenadas (seguir a hierarquia)

df_status.groupby('type1').agg(
    {
        'base_total': ['count','mean','min','max','std'],
        'attack'    : ['mean','min','max','std'],
        'hp'        : ['mean','min','max','std'],
        'generation': ['min','max']
    }
    ).sort_values(('base_total','mean'),ascending=False).round(1)

# Será que a cada geração que passa os pokémons ficam mais fortes ou fracos ?

df_status.groupby('generation').agg(
    {'base_total' : ['count','mean','min','max','std']}
    ).round(1)

# Comparação entre lendários e não lendários

print('\n \t \t Média por *atributo* entre lendários e não lendários! \n')

df_status.groupby('is_legendary').agg(
        Base_Total = ('base_total','mean'),
        HP         = ('hp','mean'),
        Attack     = ('attack','mean'),
        Sp_Attack  = ('sp_attack','mean'),
        Speed      = ('speed','mean'),
        Defense    = ('defense','mean'),
        Sp_Defense = ('sp_defense','mean')
    ).sort_values('Base_Total',ascending=False).round(1)

"""# **Vamos fazer alguns gráficos !**

    * O título já diz muito :)
    * Deixei alguns códigos pra quem tem curiosidade de saber como montar alguns gráficos em Python das bibliotecas MatplotLib e Seaborn
     (documentação é grande, recomendo a leitura aos poucos)

"""

import seaborn as sns
import matplotlib.pyplot as plt

fig, ax = plt.subplots()

plt.rcParams["figure.figsize"] = (8,4)

# GRÁFICO DE LINHA
# ax.plot(
#     df_status.groupby('generation').agg(media_total = ('base_total','mean')).iloc[:,0].index,
#     df_status.groupby('generation').agg(media_total = ('base_total','mean')).iloc[:,0].values,
#     linewidth = 1.0,
#     color = 'orange',
#     marker = 'o',
#     markersize = '6',
#     linestyle = '--',
#     label = 'Média de base_total')


#GRÁFICO DE BARRA VERTICAL
ax.bar(
    df_status.groupby('generation').agg(media_total = ('base_total','mean')).iloc[:,0].index,
    df_status.groupby('generation').agg(media_total = ('base_total','mean')).iloc[:,0].values,
    width = 0.5,
    label = 'Média',
    color = 'orange',
    alpha = 0.8)

ax.set_ylabel('Base Total')
ax.set_xlabel('Geração')
ax.legend()
plt.show()

plt.rcParams["figure.figsize"] = (8,4)

df_status.plot(x='hp',y='attack',kind='scatter');
# df_status.plot(x='hp',y='defense',kind='scatter')
# df_status.plot(x='hp',y='sp_attack',kind='scatter')
# df_status.plot(x='hp',y='sp_defense',kind='scatter')
# df_status.plot(x='hp',y='speed',kind='scatter');

df_plot = df_status.groupby('type1').agg(
        HP         = ('hp','mean'),
        Attack     = ('attack','mean'),
        Sp_Attack  = ('sp_attack','mean'),
        Speed      = ('speed','mean'),
        Defense    = ('defense','mean'),
        Sp_Defense = ('sp_defense','mean'),
        Base_Total = ('base_total','mean')
    ).sort_values('Base_Total',ascending=False).round(1)

plt.rcParams["figure.figsize"] = (15,8)

# Desconsidero a ultima coluna (Base Total) porque ela serviu apenas para ordenar o df_plot do maior "Base_Total" para o menor
df_plot.iloc[:,:-1].plot(kind='bar',
                         stacked=True,
                         colormap='PuOr'
                         );


# Padrão de cores (colormap) fornecido pela documentação:
# "https://matplotlib.org/stable/tutorials/colors/colormaps.html"

# Ver a correlação entre os principais atributos dos pokémons

df_corr = df_plot[df_plot.columns[:-1]].corr().round(2)

sns.heatmap(df_corr,cmap='PuOr',annot = True);

# BÔNUS: correlação com filtro por tipo de pokémon

tipos = ['bug', 'dark', 'dragon', 'electric', 'fairy', 'fighting', 'fire','flying', 'ghost', 'grass',
        'ground', 'ice', 'normal', 'poison', 'psychic', 'rock', 'steel', 'water']

tipo = 'bug'

df_corr_tipo = df_status[df_status.type1==tipo][['hp','attack','defense','speed','sp_attack','sp_defense']].corr().round(2)

print(f'Tipo do Pokémon: {tipo} \nTamanho da amostra: {len(df_status[df_status.type1==tipo])}')

sns.heatmap(df_corr_tipo,cmap='PuOr',annot = True);

"""## **Vamos supor que você queira ver a correlação cruzada de cada atributo olhando para cada tipo de pokémon. Meio complexo mas nunca se sabe a necessidade disso...**

**Por isso pensei em montar duas funções:**

      1. single_cross_corr : função que vai capturar cada valor da tabela de
      correlações (ignorando os valores repetidos, por exemplo os 1's na 
      diagonal)

      2. cross_corr: está vai passar por cada tipo de pokemon em uma lista e
      adicionar cada um dos valores em um dataframe pra consolidar todos os
      valores
"""

def single_cross_corr(data_frame,pkm_type = 'bug',cols_corr = ['hp','attack','defense','speed','sp_attack','sp_defense']):

    lst_cols = []
    lst_values = []
    row = 0
    start_column = 1

    df_single_cross = data_frame[data_frame.type1==pkm_type][cols_corr].corr().round(2)
        
    while row < len(df_single_cross)-1:

        lst_cols.extend(df_single_cross.index[row]+ ' x ' + df_single_cross.columns[start_column:])

        lst_values.extend(df_single_cross.values[row][start_column:])
            
        start_column +=1

        row += 1

    cross = pd.DataFrame(lst_values).T # T significa trazer a matriz transposta (Trocar linha por coluna)
    cross.columns = lst_cols
    cross.rename(index = {0:pkm_type},inplace=True)

    return cross

def cross_corr(data_frame):

    df_cross_corr = pd.DataFrame()

    tipos = ['bug', 'dark', 'dragon', 'electric', 'fairy', 
             'fighting','fire','flying', 'ghost', 'grass',
             'ground', 'ice', 'normal', 'poison', 'psychic',
             'rock', 'steel', 'water']

    for tp in tipos:
        
        df_cross_corr = df_cross_corr.append(single_cross_corr(data_frame,tp))

    return df_cross_corr

"""No final é só chamar a função **cross_corr** e colocar como parâmetro a tabela principal criada por nós (no caso a "df_status")"""

# Aqui está todos os valores das correlações dos atributos de cada pokémon
# Nas colunas quais as variáveis que são comparadas e nas linhas os tipos de pokemon

cross_corr(df_status)

"""# **Preparando a base para os modelos de clusters**"""

# Separando variáveis categóricas das numéricas (a.k.a. Boas Práticas)

var_cat  = ['type1','type2','classfication','generation','is_legendary']
var_num  = ['hp', 'attack', 'defense', 'speed', 'sp_attack', 'sp_defense','capture_rate','height_m','weight_kg']

!pip install --upgrade feature_engine

# Vou tirar a coluna de tipo2 e classfication porque elas não acrescentam muito e deixam o modelo mais complexo(desnecessariamente)
df_abt_cluster = df_status.drop(columns=['type2','classfication','generation','is_legendary','height_m','weight_kg'],axis=1)

# Para rodar os modelos de clusters, precisamos transformar a variável categórica "type1" em numérica
# Vamos utilizar a biblioteca feature engine para transformar o tipo do pokémon no valor da sua frequência

from feature_engine.encoding import CountFrequencyEncoder

cfe = CountFrequencyEncoder(encoding_method='count',variables='type1')

df_abt_cluster = cfe.fit_transform(df_abt_cluster)

#!pip install --upgrade category_encoders

# Vamos rodar alguns modelos e, por isso, vou deixar um dicionário para guardar as métricas de cada um

dic = {}

"""# **Hora de rodar algoritmos de Clusterização:**

### Kmeans
"""

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=3,random_state=42)

kmeans.fit(df_abt_cluster)

# Vamos plotar alguns gráficos com os centróides encontrados pelo KMeans

plt.scatter(
    x    = df_abt_cluster.hp,
    y    = df_abt_cluster.attack,
    c    = kmeans.labels_,
    cmap = 'viridis');

plt.scatter(
    x = kmeans.cluster_centers_[:,0],
    y = kmeans.cluster_centers_[:,1],
    c = 'red',
    s=150);

from sklearn.metrics import silhouette_score

score = silhouette_score(df_abt_cluster,kmeans.labels_)

# Entre 0 e 1, quanto maior...melhor...(Mais bem definido os grupos foram identificados, sem muita sobreposição)
print(f'Silhouette score: {score:.5f}')

# Vamos facilitar nossa vida e utilizar a biblioteca yellowbrick pra descobrir o melhor numero de grupos no KMeans
!pip install yellowbrick==1.2

from yellowbrick.cluster import SilhouetteVisualizer

silhoutte = SilhouetteVisualizer(kmeans)
silhoutte.fit(X=df_abt_cluster);

from yellowbrick.cluster import KElbowVisualizer

model = KMeans()
visualizer = KElbowVisualizer(model, k=(2,20)) #rodar o kmeans com n de clusters de 2 a 20
visualizer.fit(df_abt_cluster)
visualizer.show();

# De acordo com o gráfico o nº de clusters mais eficiente é o 6
kmeans = KMeans(n_clusters=5,random_state=42)

kmeans.fit(df_abt_cluster)

# Vamos plotar alguns gráficos com os centróides encontrados pelo KMeans

plt.scatter(x = df_abt_cluster.hp,
            y = df_abt_cluster.attack,
            c = kmeans.labels_,
            cmap='viridis');

plt.scatter(x = kmeans.cluster_centers_[:,0],
            y = kmeans.cluster_centers_[:,1],
            c = 'red',
            s=100,);

score = silhouette_score(df_abt_cluster,kmeans.labels_)
print(f'Silhouette score: {score:.5f}')

silhoutte = SilhouetteVisualizer(kmeans)
silhoutte.fit(X=df_abt_cluster);

dic['Kmeans'] = score

df_status['Kmeans'] = kmeans.labels_

# Estatísticas gerais de cada grupo

pd.crosstab(
    df_status['Kmeans'],
    df_status['is_legendary'],
    values  = df_status['base_total'],
    aggfunc = ('count','mean')
    ).fillna(0).round(1)

# Apenas para consulta da lista de pokémon em cada grupo:

num_grupo = 3
lendario  = 0

df_status[(df_status['Kmeans']==num_grupo) & (df_status['is_legendary']==lendario)]

"""### Affinity Propagation"""

from sklearn.cluster import AffinityPropagation

model = AffinityPropagation(damping=0.9)

y_cluster = model.fit_predict(df_abt_cluster)

clusters = np.unique(y_cluster)
clusters

plt.figure(figsize=(10,8))

for cluster in clusters:

    linhas_do_grupo = np.where(y_cluster==cluster)

    plt.scatter(df_status.iloc[linhas_do_grupo]['hp'],df_status.iloc[linhas_do_grupo]['attack'])

plt.show()

# Conferência dos pokémons em cada cluster formado pelo AffinityPropagation
df_status.iloc[np.where(y_cluster==1)]

score = silhouette_score(df_abt_cluster,model.labels_)

# Entre 0 e 1, quanto maior...melhor...(Mais bem definido os grupos foram identificados, sem muita sobreposição)
print(f'Silhouette score: {score:.5f}')

dic['AffinityPropagation'] = score

"""### Agglomerative Clustering"""

from sklearn.cluster import AgglomerativeClustering

model = AgglomerativeClustering(n_clusters=5)

y_cluster = model.fit_predict(df_abt_cluster)

clusters = np.unique(y_cluster)
clusters

for cluster in clusters:

    linhas_do_grupo = np.where(y_cluster==cluster)

    plt.scatter(df_status.iloc[linhas_do_grupo]['hp'],df_status.iloc[linhas_do_grupo]['attack'])

plt.legend(clusters.tolist())
plt.show()

# Conferência dos pokémons em cada cluster formado pelo AgglomerativeClustering
df_status.iloc[np.where(y_cluster==3)]

score = silhouette_score(df_abt_cluster,y_cluster)

# Entre 0 e 1, quanto maior...melhor...(Mais bem definido os grupos foram identificados, sem muita sobreposição)
print(f'Silhouette score: {score:.5f}')

dic['AgglomerativeClustering'] = score

"""### BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)"""

from sklearn.cluster import Birch

model = Birch(n_clusters=5,threshold=0.1)

y_cluster = model.fit_predict(df_abt_cluster)

clusters = np.unique(y_cluster)
clusters

for cluster in clusters:

    linhas_do_grupo = np.where(y_cluster==cluster)

    plt.scatter(df_status.iloc[linhas_do_grupo]['hp'],df_status.iloc[linhas_do_grupo]['attack'])

plt.legend(clusters.tolist())
plt.show()

# Conferência dos pokémons em cada cluster formado pelo BIRCH
print(df_status.iloc[np.where(y_cluster==0)]['base_total'].mean())
print(df_status.iloc[np.where(y_cluster==1)]['base_total'].mean())
print(df_status.iloc[np.where(y_cluster==2)]['base_total'].mean())
print(df_status.iloc[np.where(y_cluster==3)]['base_total'].mean())
print(df_status.iloc[np.where(y_cluster==4)]['base_total'].mean())

score = silhouette_score(df_abt_cluster,y_cluster)

# Entre 0 e 1, quanto maior...melhor...(Mais bem definido os grupos foram identificados, sem muita sobreposição)

print(f'Silhouette score: {score:.5f}')

dic['BIRCH'] = score

"""### DBSCAN"""

from sklearn.cluster import DBSCAN

from feature_engine.wrappers import SklearnTransformerWrapper
from sklearn.preprocessing import MinMaxScaler

std_scaler = SklearnTransformerWrapper(transformer = MinMaxScaler())

df_abt_standardized = std_scaler.fit_transform(df_abt_cluster)

df_abt_standardized.describe().round(3)

model = DBSCAN(eps=0.225,min_samples=5)

y_cluster = model.fit_predict(df_abt_standardized)

clusters = np.unique(y_cluster)
clusters

pd.Series(y_cluster).value_counts()

score = silhouette_score(df_abt_standardized,y_cluster)

# Entre 0 e 1, quanto maior...melhor...(Mais bem definido os grupos foram identificados, sem muita sobreposição)

print(f'Silhouette score: {score:.5f}')

dic['DBSCAN'] = score

for cluster in clusters:

    linhas_do_grupo = np.where(y_cluster==cluster)

    plt.scatter(df_status.iloc[linhas_do_grupo]['hp'],df_status.iloc[linhas_do_grupo]['attack'])

plt.legend(clusters.tolist())
plt.show()

"""### Resumo dos modelos"""

# Vamos criar a series com os valores da métrica Silhouette para comparar os modelos
# O parâmetro "orient" é pra indicar se as chaves do dic serão usados como colunas ou índices

pd.DataFrame.from_dict(dic, orient='index',columns=['Silhouette Score'])

pd.Series(data  = dic,
          index = dic.keys(),
          name='Silhoutte Score')